{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPaqUeKmBVVX",
        "outputId": "466335e3-a9f8-43cb-c711-b2c665727511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: Obama-to-Biden.wav\n",
            "Processing file: Obama-to-Trump.wav\n",
            "Processing file: biden-to-Obama.wav\n",
            "Processing file: biden-to-Trump.wav\n",
            "Processing file: biden-to-linus.wav\n",
            "Processing file: biden-to-margot.wav\n",
            "Processing file: biden-to-musk.wav\n",
            "Processing file: biden-to-ryan.wav\n",
            "Processing file: biden-to-taylor.wav\n",
            "Processing file: linus-to-biden.wav\n",
            "Processing file: linus-to-margot.wav\n",
            "Processing file: linus-to-musk.wav\n",
            "Processing file: linus-to-obama.wav\n",
            "Processing file: linus-to-ryan.wav\n",
            "Processing file: linus-to-taylor.wav\n",
            "Processing file: margot-to-biden.wav\n",
            "Processing file: linus-to-trump.wav\n",
            "Processing file: margot-to-linus.wav\n",
            "Processing file: margot-to-musk.wav\n",
            "Processing file: margot-to-obama.wav\n",
            "Processing file: margot-to-ryan.wav\n",
            "Processing file: margot-to-taylor.wav\n",
            "Processing file: margot-to-trump.wav\n",
            "Processing file: musk-to-biden.wav\n",
            "Processing file: musk-to-linus.wav\n",
            "Processing file: musk-to-margot.wav\n",
            "Processing file: musk-to-obama.wav\n",
            "Processing file: musk-to-ryan.wav\n",
            "Processing file: musk-to-taylor.wav\n",
            "Processing file: musk-to-trump.wav\n",
            "Processing file: obama-to-linus.wav\n",
            "Processing file: obama-to-margot.wav\n",
            "Processing file: obama-to-musk.wav\n",
            "Processing file: obama-to-ryan.wav\n",
            "Processing file: obama-to-taylor.wav\n",
            "Processing file: ryan-to-biden.wav\n",
            "Processing file: ryan-to-linus.wav\n",
            "Processing file: ryan-to-margot.wav\n",
            "Processing file: ryan-to-musk.wav\n",
            "Processing file: ryan-to-obama.wav\n",
            "Processing file: ryan-to-trump.wav\n",
            "Processing file: ryan-to-taylor.wav\n",
            "Processing file: taylor-to-biden.wav\n",
            "Processing file: taylor-to-linus.wav\n",
            "Processing file: taylor-to-margot.wav\n",
            "Processing file: taylor-to-musk.wav\n",
            "Processing file: taylor-to-obama.wav\n",
            "Processing file: taylor-to-ryan.wav\n",
            "Processing file: taylor-to-trump.wav\n",
            "Processing file: trump-to-Biden.wav\n",
            "Processing file: trump-to-Obama.wav\n",
            "Processing file: trump-to-linus.wav\n",
            "Processing file: trump-to-margot.wav\n",
            "Processing file: trump-to-musk.wav\n",
            "Processing file: trump-to-ryan.wav\n",
            "Processing file: trump-to-taylor.wav\n",
            "Processing file: biden-original.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=143\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: margot-original.wav\n",
            "Processing file: linus-original.wav\n",
            "Processing file: musk-original.wav\n",
            "Processing file: ryan-original.wav\n",
            "Processing file: obama-original.wav\n",
            "Processing file: taylor-original.wav\n",
            "Processing file: trump-original.wav\n",
            "          mfcc_0      mfcc_1      mfcc_2     mfcc_3     mfcc_4     mfcc_5  \\\n",
            "0    -344.940247  184.372253  -53.522011 -10.656567 -31.722338   0.496074   \n",
            "1    -331.827148  180.274582  -66.526703   2.252668 -26.897394   8.383003   \n",
            "2    -301.955811  203.748108 -100.482590 -13.155165 -38.819607 -17.975796   \n",
            "3    -268.484070  208.112518 -109.855804 -19.142450 -45.374626 -19.284824   \n",
            "4    -287.688446  210.582413  -98.025452 -15.918679 -48.244888 -12.454594   \n",
            "...          ...         ...         ...        ...        ...        ...   \n",
            "3745 -359.348450  143.910110  -53.743927  12.865443 -21.503048  -5.505956   \n",
            "3746 -342.633911  168.411026  -63.005383  27.147928 -13.705704  21.142042   \n",
            "3747 -294.075684  198.536072  -86.627548   6.403258 -32.057777 -14.217331   \n",
            "3748 -301.610474  197.853989 -122.178337  -5.519490 -54.083290 -31.807774   \n",
            "3749 -293.836761  189.785080 -100.382469  -0.197557 -42.886623 -17.291779   \n",
            "\n",
            "         mfcc_6     mfcc_7     mfcc_8     mfcc_9  ...  chroma_mean  \\\n",
            "0    -24.274515  -9.841029   4.568827 -17.641817  ...     0.296646   \n",
            "1    -16.158304  -5.559877  -1.349264 -28.266977  ...     0.394531   \n",
            "2    -15.752688 -13.392586   7.146380  -7.956029  ...     0.448645   \n",
            "3    -19.717094 -12.726741   3.960034 -10.665652  ...     0.475463   \n",
            "4    -20.471315 -13.984996   9.551799 -13.080670  ...     0.474444   \n",
            "...         ...        ...        ...        ...  ...          ...   \n",
            "3745  -0.732483 -21.000731  -2.971955 -11.660328  ...     0.390133   \n",
            "3746  -4.620003 -29.095797   1.596248 -17.957058  ...     0.366857   \n",
            "3747  -8.431772 -23.637997   3.408744 -14.671774  ...     0.415532   \n",
            "3748 -14.293084 -38.791965  10.344762 -24.906504  ...     0.401424   \n",
            "3749 -21.250725 -33.080177   2.913193 -18.275953  ...     0.442513   \n",
            "\n",
            "      spectral_centroid  spectral_bandwidth  spectral_rolloff  \\\n",
            "0           1960.855092         2397.604729       3249.335106   \n",
            "1           2372.559917         2563.034624       3929.271941   \n",
            "2           1955.507834         2054.982611       3153.839761   \n",
            "3           1885.870602         1855.233947       3033.909574   \n",
            "4           1817.515513         1932.325273       2789.062500   \n",
            "...                 ...                 ...               ...   \n",
            "3745        2892.656719         2842.183001       4899.684176   \n",
            "3746        2474.593146         2710.469134       4212.516622   \n",
            "3747        2018.792188         2187.654558       3441.073803   \n",
            "3748        2110.993781         2117.651504       3447.805851   \n",
            "3749        2152.718613         2290.895357       3471.608232   \n",
            "\n",
            "      zero_crossing_rate  rms_energy  type  interval_start  interval_end  \\\n",
            "0               0.049810    0.044592  REAL             0.0      1.000000   \n",
            "1               0.070120    0.029868  REAL             1.0      2.000000   \n",
            "2               0.051493    0.037872  REAL             2.0      3.000000   \n",
            "3               0.051831    0.055642  REAL             3.0      4.000000   \n",
            "4               0.049072    0.046571  REAL             4.0      5.000000   \n",
            "...                  ...         ...   ...             ...           ...   \n",
            "3745            0.080696    0.030664  REAL           596.0    597.000000   \n",
            "3746            0.061575    0.035883  REAL           597.0    598.000000   \n",
            "3747            0.050885    0.041512  REAL           598.0    599.000000   \n",
            "3748            0.056983    0.038251  REAL           599.0    600.000000   \n",
            "3749            0.051484    0.037529  REAL           600.0    600.430938   \n",
            "\n",
            "               file_name  \n",
            "0     biden-original.wav  \n",
            "1     biden-original.wav  \n",
            "2     biden-original.wav  \n",
            "3     biden-original.wav  \n",
            "4     biden-original.wav  \n",
            "...                  ...  \n",
            "3745  trump-original.wav  \n",
            "3746  trump-original.wav  \n",
            "3747  trump-original.wav  \n",
            "3748  trump-original.wav  \n",
            "3749  trump-original.wav  \n",
            "\n",
            "[3750 rows x 23 columns]\n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Function to extract features from an audio segment\n",
        "def extract_features(y, sr):\n",
        "\n",
        "    features = {}\n",
        "    features.update({f\"mfcc_{i}\": val for i, val in enumerate(np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13), axis=1))})\n",
        "    features[\"chroma_mean\"] = np.mean(librosa.feature.chroma_stft(y=y, sr=sr))  # Single chroma feature (mean of all bins)\n",
        "    features[\"spectral_centroid\"] = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
        "    features[\"spectral_bandwidth\"] = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
        "    features[\"spectral_rolloff\"] = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
        "    features[\"zero_crossing_rate\"] = np.mean(librosa.feature.zero_crossing_rate(y=y))\n",
        "    features[\"rms_energy\"] = np.mean(librosa.feature.rms(y=y))\n",
        "    return features\n",
        "\n",
        "# Function to process an audio file in 1-second intervals\n",
        "def process_audio_in_intervals(file_path, type, interval_duration=1):\n",
        "    y, sr = librosa.load(file_path, sr=None)  # Load audio file\n",
        "    interval_samples = sr * interval_duration  # Number of samples per interval\n",
        "\n",
        "    features_list = []\n",
        "    total_samples = len(y)\n",
        "\n",
        "    # Iterate over intervals\n",
        "    for start_sample in range(0, total_samples, interval_samples):\n",
        "        end_sample = min(start_sample + interval_samples, total_samples)\n",
        "        y_segment = y[start_sample:end_sample]  # Extract segment\n",
        "\n",
        "        # Extract features for this segment\n",
        "        features = extract_features(y_segment, sr)\n",
        "        features[\"type\"] = type  # Add type (real or fake)\n",
        "        features[\"interval_start\"] = start_sample / sr  # Start time of the interval (in seconds)\n",
        "        features[\"interval_end\"] = end_sample / sr  # End time of the interval (in seconds)\n",
        "        features_list.append(features)\n",
        "\n",
        "    return features_list\n",
        "\n",
        "# Function to process all files in a directory\n",
        "def process_directory(directory_path, type, interval_duration=1):\n",
        "    all_features = []\n",
        "    for file_name in os.listdir(directory_path):\n",
        "        file_path = os.path.join(directory_path, file_name)\n",
        "        if os.path.isfile(file_path) and file_name.lower().endswith(('.wav', '.mp3', '.flac')):  # Check for audio files\n",
        "            print(f\"Processing file: {file_name}\")\n",
        "            file_features = process_audio_in_intervals(file_path, type,interval_duration)\n",
        "            for feature_set in file_features:\n",
        "                feature_set[\"file_name\"] = file_name  # Add file name for reference\n",
        "            all_features.extend(file_features)\n",
        "\n",
        "    return pd.DataFrame(all_features)\n",
        "\n",
        "# Example usage\n",
        "directory_path = \"/content/drive/MyDrive/KAGGLE/AUDIO/FAKE\"  # Replace with the path to your directory\n",
        "df = process_directory(directory_path, \"FAKE\")\n",
        "df.to_csv(\"FAKE_audio_features_directory.csv\", index=False)\n",
        "# Example usage\n",
        "directory_path = \"/content/drive/MyDrive/KAGGLE/AUDIO/REAL\"  # Replace with the path to your directory\n",
        "df2 = process_directory(directory_path, \"REAL\")\n",
        "#combined_df = pd.concat([df, df2], axis=1)\n",
        "\n",
        "# Save to CSV\n",
        "#combined_df.to_csv(\"combined_columns.csv\", index=False)\n",
        "# Save to a CSV file (optional)\n",
        "df2.to_csv(\"REAL_audio_features_directory.csv\", index=False)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the provided CSV files\n",
        "real_audio_features_path = '/content/drive/MyDrive/KAGGLE/REAL_audio_features_directory.csv'\n",
        "fake_audio_features_path = '/content/drive/MyDrive/KAGGLE/FAKE_audio_features_directory.csv'\n",
        "\n",
        "real_audio_features = pd.read_csv(real_audio_features_path)\n",
        "fake_audio_features = pd.read_csv(fake_audio_features_path)\n",
        "\n",
        "# Combine the datasets and label them appropriately\n",
        "audio_features = pd.concat([real_audio_features, fake_audio_features], ignore_index=True)\n",
        "audio_features.to_csv(\"audio_features.csv\", index=False)\n",
        "\n",
        "# Drop non-feature columns that are not useful for training\n",
        "columns_to_drop = ['file_name', 'interval_start', 'interval_end', 'type']  # 'type' will be used as the label\n",
        "X = audio_features.drop(columns=columns_to_drop)\n",
        "y = audio_features['type'].map({'REAL': 0, 'FAKE': 1})  # Encode labels as 0 for REAL and 1 for FAKE\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)  # Using 5 neighbors as a default\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "y_pred = knn.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUykELNAFYir",
        "outputId": "0c490271-eca8-4292-d46e-a8384e65e832"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 98.56%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.92      0.94       750\n",
            "           1       0.99      0.99      0.99      5243\n",
            "\n",
            "    accuracy                           0.99      5993\n",
            "   macro avg       0.97      0.96      0.97      5993\n",
            "weighted avg       0.99      0.99      0.99      5993\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the provided CSV files\n",
        "real_audio_features_path = '/content/drive/MyDrive/KAGGLE/REAL_audio_features_directory.csv'\n",
        "fake_audio_features_path = '/content/drive/MyDrive/KAGGLE/FAKE_audio_features_directory.csv'\n",
        "\n",
        "real_audio_features = pd.read_csv(real_audio_features_path)\n",
        "fake_audio_features = pd.read_csv(fake_audio_features_path)\n",
        "\n",
        "# Combine the datasets and label them appropriately\n",
        "audio_features = pd.concat([real_audio_features, fake_audio_features], ignore_index=True)\n",
        "\n",
        "# Drop non-feature columns that are not useful for training\n",
        "columns_to_drop = ['file_name', 'interval_start', 'interval_end']  # Drop metadata\n",
        "X = audio_features.drop(columns=columns_to_drop + ['type'])  # Keep all 19 feature columns\n",
        "y = audio_features['type'].map({'REAL': 0, 'FAKE': 1})  # Encode labels as 0 for REAL and 1 for FAKE\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize the features (necessary for SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the SVM classifier\n",
        "svm = SVC(kernel='linear', C=1.0, random_state=42)  # Linear kernel and regularization parameter C=1.0\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "y_pred = svm.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS7eYWBnLdkR",
        "outputId": "2c2eccb3-d41f-40e0-bbd9-1c46347ad8ff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 93.54%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.57      0.69       750\n",
            "           1       0.94      0.99      0.96      5243\n",
            "\n",
            "    accuracy                           0.94      5993\n",
            "   macro avg       0.91      0.78      0.83      5993\n",
            "weighted avg       0.93      0.94      0.93      5993\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the provided CSV files\n",
        "real_audio_features_path = '/content/drive/MyDrive/KAGGLE/REAL_audio_features_directory.csv'\n",
        "fake_audio_features_path = '/content/drive/MyDrive/KAGGLE/FAKE_audio_features_directory.csv'\n",
        "\n",
        "real_audio_features = pd.read_csv(real_audio_features_path)\n",
        "fake_audio_features = pd.read_csv(fake_audio_features_path)\n",
        "\n",
        "# Combine the datasets and label them appropriately\n",
        "audio_features = pd.concat([real_audio_features, fake_audio_features], ignore_index=True)\n",
        "\n",
        "# Drop non-feature columns that are not useful for training\n",
        "columns_to_drop = ['file_name', 'interval_start', 'interval_end']  # Drop metadata\n",
        "X = audio_features.drop(columns=columns_to_drop + ['type'])  # Keep all 19 feature columns\n",
        "y = audio_features['type'].map({'REAL': 0, 'FAKE': 1})  # Encode labels as 0 for REAL and 1 for FAKE\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize the features (Naive Bayes doesn't require this but can help with certain feature ranges)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "naive_bayes = GaussianNB()\n",
        "naive_bayes.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "y_pred = naive_bayes.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN_o7g9gPNri",
        "outputId": "78b633bc-101d-4ac9-b0e7-861d4061c684"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 84.20%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.46      0.42       750\n",
            "           1       0.92      0.90      0.91      5243\n",
            "\n",
            "    accuracy                           0.84      5993\n",
            "   macro avg       0.65      0.68      0.66      5993\n",
            "weighted avg       0.85      0.84      0.85      5993\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}